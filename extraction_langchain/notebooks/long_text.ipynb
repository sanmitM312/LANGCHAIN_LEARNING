{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from schemas_diff import Other_Benefits\n",
    "\n",
    "from retrieval_prompts import RETRIEVAL_SYSTEM_PROMPT_2,RETRIEVAL_HUMAN_PROMPT_TEMPLATE_3,RETRIEVAL_HUMAN_PROMPT_TEMPLATE_4\n",
    "\n",
    "from  dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langchain_community' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLangChain version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mlangchain_community\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'langchain_community' is not defined"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\n",
    "        \"\\n\\n\",          # Split on paragraphs\n",
    "        \"\\n---+\\n\",      # Split on horizontal lines (common in tables)\n",
    "        r'\\n\\s*\\|\\s*\\n', # Split on pipe-separated table rows\n",
    "        r'\\n\\s{2,}',     # Split on lines with 2+ spaces (common in tabular data)\n",
    "        \"\\n\",            # Split on newlines\n",
    "        r'(?<=\\. )',     # Split after sentences\n",
    "        r'\\s{4,}',       # Split on 4+ whitespace characters (tabular columns)\n",
    "        \" \",             # Split on single spaces\n",
    "        \"\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "uin = '136N080V02'\n",
    "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "persistent_directory = os.path.join(parent_dir, \"db\", f\"chroma_db_{uin}\")\n",
    "\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(f\"----Vector DB does not exist for UIN {uin}, creating a new one----\")\n",
    "    os.makedirs(persistent_directory)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cloudcraftz/WORK/LANGCHAIN_LEARNING/extraction_langchain/db/chroma_db_136N080V02'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._persist_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in DB: 460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total documents in DB: {len(db.get()['documents'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    \"search_type\": \"similarity_score_threshold\",\n",
    "    \"search_kwargs\": {\"k\": 1, \n",
    "                      \"score_threshold\": 0.4,\n",
    "                      }  # Exclude empty content\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_retriever = db.as_retriever(\n",
    "        search_type=search_params[\"search_type\"],\n",
    "        search_kwargs=search_params[\"search_kwargs\"]\n",
    "    )   \n",
    "# Test the retriever directly\n",
    "# query = \"What are the plan options available for this policy? Give brief description of each plan option.\"\n",
    "# result = retriever.invoke(query)\n",
    "# print(\"---------------RESPONSE-----------\",result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(os.environ.get(\"MODEL_OPENAI\"), model_provider=\"openai\", temperature=0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    formatted = []\n",
    "    for doc in docs:\n",
    "        # Ensure page_content is never None\n",
    "        content = doc.page_content or \"[EMPTY CONTENT]\"\n",
    "        formatted.append(f\"Document Content: {content}\\nMetadata: {doc.metadata}\")\n",
    "    return \"\\n\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan_Options(BaseModel):\n",
    "    value: Optional[str] = Field(\n",
    "        ..., description=\"Available plan options with their plan description and statistical details\"\n",
    "    )\n",
    "    page_number: Optional[str] = Field(\n",
    "        ..., description=\"Page number where the field was extracted from\"\n",
    "    )\n",
    "    chunks: Optional[List[str]] = Field(\n",
    "        ...,\n",
    "        description=\"Source of the chunks, keep it empty if null\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template =\"\"\"You are an expert at extracting relevant insurance policy information from text, given a query and retrieved relevant documents to the query.\n",
    "    ### Instructions:\n",
    "        1. Ensure that your analysis is detailed, accurate, concise, user-friendly, and directly addresses the query.\n",
    "            - If certain details are missing, explicitly state that the information is not available.\n",
    "        2. Compile a Final Answer:\\n- Craft a summary that is detailed, thorough, in-depth, and complex, while maintaining clarity and conciseness.\n",
    "            - Incorporate main ideas and essential information, eliminating extraneous language and focusing on critical aspects.\n",
    "            - Rely strictly on the provided text, without including external information.\n",
    "        3. Ensure that response should not provide any financial advice. If the user asks for financial advice, clearly state that you are unable to give any advice.\n",
    "        4. Ensure that the response is detailed, comprehensive, and clearly states if any critical information is missing.\n",
    "        5. Format the response in clear, easy-to-understand, point-wise format e.g 1. , 2.,  3. etc.optimized for excel cells.Make the keywords to be clearly spaced with their brief details, For e.g . in the text Life Option:- This plan provides basic life coverage, ensuring that the policyholder's beneficiaries. Do not highlight numbers, for example instead of `95,20,000`, give output as \\u20b995,20,000.\n",
    "        6. Please provide direct answers without preemptive phrases.\n",
    "        7. If the answer is not found in the documents, respond with 'Not available' ONLY. Do not generate hallucinated responses.\n",
    "    \"\"\"\n",
    "plan_options_human_template= \"\"\"\n",
    "\n",
    "    Use the following retrieved documents to extract policy details for the query follwed by the instructions.\n",
    "    ###Context:\n",
    "        Retrieved documents : {documents}\n",
    "        Query:{query}\n",
    "    \n",
    "    An example of the output format is given below:\n",
    "    3 Plan Options\n",
    "        1) Life Secure: SAD is paid if the Life Assured/Spouse dies during the PT while the policy is in-force;\n",
    "        2) Life Secure with Income: Monthly Survival Income starts at age 60 and continues until death or end of the PT. If the Life Assured dies, the SAD- paid incomes, is paid and the policy ends;\n",
    "        3) Life Secure with ROP: SAD is paid if the Life Assured dies and the Policy ends. If the Life Assured survives, the SAM is paid and the Policy ends ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_options_ext_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \n",
    "            \"\"\"You are an expert at extracting relevant insurance policy information from text, given a query and retrieved relevant documents to the query.\n",
    "            ### Instructions:\n",
    "                1. Ensure that your analysis is detailed, accurate, concise, user-friendly, and directly addresses the query.\n",
    "                    - If certain details are missing, explicitly state that the information is not available.\n",
    "                2. Compile a Final Answer:\\n- Craft a summary that is detailed, thorough, in-depth, and complex, while maintaining clarity and conciseness.\n",
    "                    - Incorporate main ideas and essential information, eliminating extraneous language and focusing on critical aspects.\n",
    "                    - Rely strictly on the provided text, without including external information.\n",
    "                3. Ensure that response should not provide any financial advice. If the user asks for financial advice, clearly state that you are unable to give any advice.\n",
    "                4. Ensure that the response is detailed, comprehensive, and clearly states if any critical information is missing.\n",
    "                5. Format the response in clear, easy-to-understand, point-wise format e.g 1. , 2.,  3. etc.optimized for excel cells.Make the keywords to be clearly spaced with their brief details, For e.g . in the text Life Option:- This plan provides basic life coverage, ensuring that the policyholder's beneficiaries. Do not highlight numbers, for example instead of `95,20,000`, give output as \\u20b995,20,000.\n",
    "                6. Please provide direct answers without preemptive phrases.\n",
    "                7. If the answer is not found in the documents, respond with 'Not available' ONLY. Do not generate hallucinated responses.\n",
    "            \"\"\"),        \n",
    "        (\"human\", \n",
    "            \"\"\" Use the following retrieved documents to extract policy details for the query follwed by the instructions.\n",
    "                ###Context:\n",
    "                    Retrieved documents : {documents}\n",
    "                    Query:{query}\n",
    "                \n",
    "                An example of the output format is given below:\n",
    "                3 Plan Options\n",
    "                    1) Life Secure: SAD is paid if the Life Assured/Spouse dies during the PT while the policy is in-force;\n",
    "                    2) Life Secure with Income: Monthly Survival Income starts at age 60 and continues until death or end of the PT. If the Life Assured dies, the SAD- paid incomes, is paid and the policy ends;\n",
    "                    3) Life Secure with ROP: SAD is paid if the Life Assured dies and the Policy ends. If the Life Assured survives, the SAM is paid and the Policy ends ;\n",
    "            \"\"\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_options_ret_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant tasked with finding the various plan options provided in an  insurance policy text.\n",
    "    Based on the following query, retrieve the relevant documents and extract the plan options.:\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_retriever(query):\n",
    "    docs = orig_retriever.invoke(query)\n",
    "    print(\"Chroma raw results:\", docs)\n",
    "    valid_docs = [doc for doc in docs if doc and doc.page_content]\n",
    "    return valid_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from typing import Any\n",
    "\n",
    "class SafeRetriever:\n",
    "    def __init__(self, base_retriever):\n",
    "        self.base_retriever = base_retriever\n",
    "\n",
    "    def invoke(self, query: str, **kwargs):\n",
    "        docs = self.base_retriever.invoke(query, **kwargs)\n",
    "        return [\n",
    "            doc for doc in docs\n",
    "            if doc and isinstance(doc, Document) and doc.page_content\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    \"search_type\": \"similarity_score_threshold\",\n",
    "    \"search_kwargs\": {\"k\": 1, \n",
    "                      \"score_threshold\": 0.4,\n",
    "                      }  # Exclude empty content\n",
    "}\n",
    "\n",
    "orig_retriever = db.as_retriever(\n",
    "        search_type=search_params[\"search_type\"],\n",
    "        search_kwargs=search_params[\"search_kwargs\"]\n",
    "    )   \n",
    "\n",
    "# safe_retriever = SafeRetriever(orig_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_output = {}\n",
    "extractor = plan_options_ext_prompt | llm.with_structured_output(\n",
    "    schema=Plan_Options,\n",
    "    include_raw=False,\n",
    ")\n",
    "\n",
    "\n",
    "def debug_retriever(query):\n",
    "    docs = orig_retriever.invoke(query)\n",
    "    print(\"Chroma raw results:\", docs)  # Inspect structure\n",
    "    return [doc for doc in docs if doc.page_content is not None]  # Filter out None\n",
    "\n",
    "def log_input(output):\n",
    "    print(\"To LLM:\", output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_options_chain = (\n",
    "    {\n",
    "        \"documents\": orig_retriever | (lambda docs : docs[0].page_content)\n",
    "    }\n",
    "    | RunnableLambda(log_input)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"Page {doc.metadata['page']}: {doc.page_content}\" \n",
    "                      for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_options_query = \"What are the plan options available for this policy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe_retriever = SafeRetriever(orig_retriever)\n",
    "docs = orig_retriever.invoke(plan_options_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _patched_results_to_docs_and_scores(results):\n",
    "    return [\n",
    "        (Document(page_content=doc, metadata=meta or {}), score)\n",
    "        for doc, meta, score in zip(\n",
    "            results[\"documents\"][0],\n",
    "            results[\"metadatas\"][0],\n",
    "            results[\"distances\"][0],\n",
    "        )\n",
    "        if doc is not None\n",
    "    ]\n",
    "\n",
    "Chroma._results_to_docs_and_scores = _patched_results_to_docs_and_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '2024-09-23T19:05:56+06:30', 'creator': 'Adobe Illustrator 27.0 (Windows)', 'moddate': '2024-09-24T18:55:02+05:30', 'page': 3, 'page_label': '4', 'producer': 'Adobe PDF library 16.07', 'source': '/tmp/tmpkqr5datr.pdf', 'title': '16-CHL_Product_iSelect Smart 360 term plan_Sales Literature_V_2 23 SEP 2024', 'total_pages': 24}, page_content='Note: Premium amounts shown are basis Physical Medical and exclusive of taxes\\nCOVERAGE OPTION\\nThe beneﬁts available under the Plan Op�on Life will be based on the Coverage Op�ons chosen by you at incep�on. Similarly, a \\nWorking Spouse can choose any of these Coverage Op�ons at policy incep�on. These op�ons, once chosen, cannot be altered \\nduring the Policy Term.\\n1. Level Cover: Your Sum Assured remains same throughout the Policy Term. However, if you have opted for regular premium')]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[279], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# retrieve the docs , pass it in the prompt , along with the query \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mplan_options_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan_options_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:3023\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3023\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:3728\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3723\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3724\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3725\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3726\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3727\u001b[0m         ]\n\u001b[0;32m-> 3728\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3729\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:3728\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3723\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3724\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3725\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3726\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3727\u001b[0m         ]\n\u001b[0;32m-> 3728\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3729\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:3712\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[0;34m(step, input, config, key)\u001b[0m\n\u001b[1;32m   3706\u001b[0m child_config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   3707\u001b[0m     config,\n\u001b[1;32m   3708\u001b[0m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   3710\u001b[0m )\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m-> 3712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/runnables/base.py:3023\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3023\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:1077\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1076\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1077\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1080\u001b[0m     )\n\u001b[1;32m   1081\u001b[0m     docs \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities]\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:555\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m0 is dissimilar, 1 is most similar.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score).\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    553\u001b[0m score_threshold \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 555\u001b[0m docs_and_similarities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_similarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    559\u001b[0m     similarity \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, similarity \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities\n\u001b[1;32m    561\u001b[0m ):\n\u001b[1;32m    562\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance scores must be between\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 0 and 1, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_and_similarities\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    565\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    566\u001b[0m     )\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:504\u001b[0m, in \u001b[0;36mVectorStore._similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Default similarity search with relevance scores. Modify if necessary\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03min subclass.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03mReturn docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    503\u001b[0m relevance_score_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_relevance_score_fn()\n\u001b[0;32m--> 504\u001b[0m docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [(doc, relevance_score_fn(score)) \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:448\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m    440\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    441\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39m[query_embedding],\n\u001b[1;32m    442\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_results_to_docs_and_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:41\u001b[0m, in \u001b[0;36m_results_to_docs_and_scores\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_results_to_docs_and_scores\u001b[39m(results: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# TODO: Chroma can do batch querying,\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# we shouldn't hard code to the 1st result\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         (Document(page_content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;241m0\u001b[39m], metadata\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}), result[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     46\u001b[0m             results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     47\u001b[0m             results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     48\u001b[0m             results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     ]\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_results_to_docs_and_scores\u001b[39m(results: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# TODO: Chroma can do batch querying,\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# we shouldn't hard code to the 1st result\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m         (\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m, result[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     46\u001b[0m             results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     47\u001b[0m             results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     48\u001b[0m             results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     ]\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/documents/base.py:285\u001b[0m, in \u001b[0;36mDocument.__init__\u001b[0;34m(self, page_content, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Pass page_content in as positional or named arg.\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# my-py is complaining that page_content is not defined on the base class.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Here, we're relying on pydantic base class to handle the validation.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WORK/LANGCHAIN_LEARNING/extraction_langchain/policy-rag/lib/python3.10/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Document\npage_content\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": [
    "# retrieve the docs , pass it in the prompt , along with the query \n",
    "\n",
    "result = plan_options_chain.invoke(plan_options_query)\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
